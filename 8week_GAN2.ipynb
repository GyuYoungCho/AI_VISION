{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "\n",
    "|Discriminant|Generative|\n",
    "|-|-|\n",
    "|linear|non-linear|\n",
    "|porbabilistic|stochastic|\n",
    "|parametric|non-parametric|\n",
    "|black box|whtie box|\n",
    "\n",
    "- feedback을 받아가면서 실제 물체와 비슷하게 만듬\n",
    "    - 실제 특성이 거절당할 때마다 배움\n",
    "- **적대적 관계에서 숨어 있는 분포를 찾아 이것을 기반으로 생성**\n",
    "    < - > autoencoder : 비교를 하면서\n",
    "    \n",
    "- 실제로 사람이 배우는 방식과 비슷\n",
    "\n",
    "**Network**\n",
    "- 순수한 머신러닝을 기법을 쓴다는 것을 암시 ( 옛날에 model이 아닌 network라 부름)\n",
    "\n",
    "</br>\n",
    "\n",
    "- 생성은 할 수 있지만 학습이 잘 안됨\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 학습 테크닉\n",
    "\n",
    "**overfitting**\n",
    "- 데이터 확보\n",
    "    - noisy 생성\n",
    "- 데이터 전처리\n",
    "- 모델 단순화\n",
    "    - feature 줄이기(filer, wrapper, embeded)\n",
    "    - 차원 축소(feature를 변형)\n",
    "- 앙상블\n",
    "    - dropout\n",
    "- regularizer : 모델 복잡하지 않게\n",
    "- early stopping\n",
    "\n",
    "\n",
    "**underfitting**\n",
    "- relu, leaky relu\n",
    "- normalization\n",
    "    - BN\n",
    "    - layer\n",
    "    - instance\n",
    "    - weight\n",
    "- initializer\n",
    "- optimizer\n",
    "- gradient clipping\n",
    "- learning rate decay\n",
    "\n",
    "\n",
    "DCGAN(Deep Convolution GAN)\n",
    "\n",
    "GAN은 간단한 예시 외에 fit을 쓰지 않음!\n",
    "\n",
    "https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "\n",
    "미술관에 간 GAN 프로젝트\n",
    "\n",
    "http://introtodeeplearning.com/  : MIT 강의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(_,_) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_train = (x_train - 127.5)/127.5\n",
    "# [-1, 1]로 정규화 -> 값이 양수, 음수 -> zero centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices(x_train).shuffle(60000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative\n",
    "\n",
    "- 숨어 있는 분포 찾기\n",
    "- 분포를 받아서 Convolution해서 생성\n",
    "\n",
    "### Leaky relu\n",
    "- 음수에서 0에 가까운 기울기를 만들어 0값을 안 가지도록 하는 것\n",
    "\n",
    "### 학습전략\n",
    "- BN\n",
    "- Conv2DTranspose\n",
    "- fiter size : vgg 3,5\n",
    "- stride로 pooling 대신 씀\n",
    "- padding same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISY_DIM = 100\n",
    "\n",
    "def make_generative_model():\n",
    "    generative_model = tf.keras.models.Sequential([\n",
    "        # bias 굳이 필요없음\n",
    "        tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(NOISY_DIM ,)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "        tf.keras.layers.Reshape((7, 7, 256)),\n",
    "        tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "        tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=2, padding='same', use_bias=False),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "        # 출력 하나로\n",
    "        tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=2, padding='same', use_bias=False),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "    ])\n",
    "    return generative_model\n",
    "\n",
    "# 예시에서는 assert를 하기 위해 add하는 식으로 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generative = make_generative_model()\n",
    "generative(tf.random.normal([1,100])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x204cc14eb70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 안된 결과\n",
    "img = generative(tf.random.normal([1,100]))\n",
    "img = img.numpy().reshape(28,28)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    discriminator = tf.keras.models.Sequential([\n",
    "        # 모델이 단순화 됨\n",
    "        tf.keras.layers.Conv2D(64, (5, 5), input_shape=(28,28,1)),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "# activation 다음 dropout\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (5, 5), strides=2),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 128)       204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 12801     \n",
      "=================================================================\n",
      "Total params: 219,393\n",
      "Trainable params: 219,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss\n",
    "- 위에서 sigmoid를 하지 않았음 -> from_logits\n",
    "\n",
    "from_logit : numerically stable (학습 안 될 때)\n",
    "\n",
    "진짜와 가짜 데이터 판별하는 능력 둘 다 기르기 -> loss 두 개 (**multi task loss**)\n",
    "\n",
    "\n",
    "#### compile에서 loss\n",
    "- 문자열\n",
    "- 소문자(객체) : 상속 재활용, callable(함수)\n",
    "- 대문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real, fake):\n",
    "    real_loss = loss(tf.ones_like(real),real)\n",
    "    fake_loss = loss(tf.ones_like(fake),fake)\n",
    "    losss = real_loss + fake_loss\n",
    "    return losss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_loss(fake):\n",
    "    return loss(tf.ones_like(fake),fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  def __call__(self, *args, **kwargs):\n",
      "    \"\"\"Wraps `call`, applying pre- and post-processing steps.\n",
      "\n",
      "    Arguments:\n",
      "      *args: Positional arguments to be passed to `self.call`.\n",
      "      **kwargs: Keyword arguments to be passed to `self.call`.\n",
      "\n",
      "    Returns:\n",
      "      Output tensor(s).\n",
      "\n",
      "    Note:\n",
      "      - The following optional keyword arguments are reserved for specific uses:\n",
      "        * `training`: Boolean scalar tensor of Python boolean indicating\n",
      "          whether the `call` is meant for training or inference.\n",
      "        * `mask`: Boolean input mask.\n",
      "      - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      "        layers do), its default value will be set to the mask generated\n",
      "        for `inputs` by the previous layer (if `input` did come from\n",
      "        a layer that generated a corresponding mask, i.e. if it came from\n",
      "        a Keras layer with masking support.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: if the layer's `call` method returns None (an invalid value).\n",
      "      RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      "    \"\"\"\n",
      "    if not hasattr(self, '_thread_local'):\n",
      "      raise RuntimeError(\n",
      "          'You must call `super().__init__()` in the layer constructor.')\n",
      "\n",
      "    # `inputs` (the first arg in the method spec) is special cased in\n",
      "    # layer call due to historical reasons.\n",
      "    # This special casing currently takes the form of:\n",
      "    # - 'inputs' must be explicitly passed. A layer cannot have zero arguments,\n",
      "    #   and inputs cannot have been provided via the default value of a kwarg.\n",
      "    # - numpy/scalar values in `inputs` get converted to tensors\n",
      "    # - implicit masks / mask metadata are only collected from 'inputs`\n",
      "    # - Layers are built using shape info from 'inputs' only\n",
      "    # - input_spec compatibility is only checked against `inputs`\n",
      "    # - mixed precision casting (autocast) is only applied to `inputs`,\n",
      "    #   not to any other argument.\n",
      "    # - setting the SavedModel saving spec.\n",
      "    inputs, args, kwargs = self._split_out_first_arg(args, kwargs)\n",
      "    input_list = nest.flatten(inputs)\n",
      "\n",
      "    # Functional Model construction mode is invoked when `Layer`s are called on\n",
      "    # symbolic `KerasTensor`s, i.e.:\n",
      "    # >> inputs = tf.keras.Input(10)\n",
      "    # >> outputs = MyLayer()(inputs)  # Functional construction mode.\n",
      "    # >> model = tf.keras.Model(inputs, outputs)\n",
      "    if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):\n",
      "      return self._functional_construction_call(inputs, args, kwargs,\n",
      "                                                input_list)\n",
      "\n",
      "    # Maintains info about the `Layer.call` stack.\n",
      "    call_context = base_layer_utils.call_context()\n",
      "\n",
      "    # Accept NumPy and scalar inputs by converting to Tensors.\n",
      "    if any(isinstance(x, (np.ndarray, float, int)) for x in input_list):\n",
      "      inputs = nest.map_structure(_convert_numpy_or_python_types, inputs)\n",
      "      input_list = nest.flatten(inputs)\n",
      "\n",
      "    # Handle `mask` propagation from previous layer to current layer. Masks can\n",
      "    # be propagated explicitly via the `mask` argument, or implicitly via\n",
      "    # setting the `_keras_mask` attribute on the inputs to a Layer. Masks passed\n",
      "    # explicitly take priority.\n",
      "    input_masks, mask_is_implicit = self._get_input_masks(\n",
      "        inputs, input_list, args, kwargs)\n",
      "    if self._expects_mask_arg and mask_is_implicit:\n",
      "      kwargs['mask'] = input_masks\n",
      "\n",
      "    # Training mode for `Layer.call` is set via (in order of priority):\n",
      "    # (1) The `training` argument passed to this `Layer.call`, if it is not None\n",
      "    # (2) The training mode of an outer `Layer.call`.\n",
      "    # (3) The default mode set by `tf.keras.backend.set_learning_phase` (if set)\n",
      "    # (4) Any non-None default value for `training` specified in the call\n",
      "    #  signature\n",
      "    # (5) False (treating the layer as if it's in inference)\n",
      "    args, kwargs, training_mode = self._set_training_mode(\n",
      "        args, kwargs, call_context)\n",
      "\n",
      "    # Losses are cleared for all sublayers on the outermost `Layer.call`.\n",
      "    # Losses are not cleared on inner `Layer.call`s, because sublayers can be\n",
      "    # called multiple times.\n",
      "    if not call_context.in_call:\n",
      "      self._clear_losses()\n",
      "\n",
      "    eager = context.executing_eagerly()\n",
      "    with call_context.enter(\n",
      "        layer=self,\n",
      "        inputs=inputs,\n",
      "        build_graph=not eager,\n",
      "        training=training_mode):\n",
      "\n",
      "      if self._autocast:\n",
      "        inputs = self._maybe_cast_inputs(inputs, input_list)\n",
      "\n",
      "      if eager:\n",
      "        call_fn = self.call\n",
      "        name_scope = self._name\n",
      "      else:\n",
      "        input_spec.assert_input_compatibility(self.input_spec, inputs,\n",
      "                                              self.name)\n",
      "        name_scope = self._name_scope()  # Avoid autoincrementing.\n",
      "        call_fn = self._autographed_call()\n",
      "\n",
      "      with ops.name_scope_v2(name_scope):\n",
      "        if not self.built:\n",
      "          self._maybe_build(inputs)\n",
      "\n",
      "        with ops.enable_auto_cast_variables(self._compute_dtype_object):\n",
      "          outputs = call_fn(inputs, *args, **kwargs)\n",
      "\n",
      "        if self._activity_regularizer:\n",
      "          self._handle_activity_regularization(inputs, outputs)\n",
      "        if self._supports_masking:\n",
      "          self._set_mask_metadata(inputs, outputs, input_masks, not eager)\n",
      "        if self._saved_model_inputs_spec is None:\n",
      "          self._set_save_spec(inputs)\n",
      "\n",
      "        return outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(discriminator.__call__))\n",
    "\n",
    "# training option : False로 주면 학습을 안함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g = tf.keras.optimizers.Adam(1e-4)\n",
    "optimizer_d = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동시에 학습\n",
    "@tf.function\n",
    "def train_step(real):\n",
    "    \n",
    "    with tf.GradientTape() as ge, tf.GradientTape() as d:\n",
    "        imgs = generative(noise,training=True)\n",
    "        real_img = discriminator(real,training = True)\n",
    "        fake_img = discriminator(imgs,training = True)\n",
    "        # 어제는 gene가 false, dis가 true 였음\n",
    "\n",
    "        # loss 정의 후 graienttape 학습\n",
    "        gen_loss = generative_loss(fake_img)\n",
    "        dis_loss = discriminator_loss(real_img, fake_img)\n",
    "\n",
    "    # loss를 variables에 관해 미분\n",
    "    gd = ge.gradient(gen_loss, generative.trainable_variables)\n",
    "    dd = d.gradient(dis_loss, discriminator.trainable_variables)\n",
    "\n",
    "    optimizer_g.apply_gradients(zip(gd, generative.trainable_variables))\n",
    "    optimizer_d.apply_gradients(zip(dd, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([BATCH_SIZE, NOISY_DIM])\n",
    "real = x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fit:epoch 별\n",
    "- train_on_batch :batch만큼\n",
    "- GradientTape: for 이용해서 epoch별 batch size만큼\n",
    "\n",
    "<br>\n",
    "\n",
    "training : 번갈아 학습 가능하도록(True,False)\n",
    "\n",
    "autoencoder : 실제 분포가 있지만 노이즈 있으면 가짜 데이터, 학습을 통해서 노이즈 제거해서 실제분포 찾음\n",
    "- 노이즈 데이터와 실제데이터 비교해서 노이즈 제거\n",
    "- 노이즈 데이터로 실제값을 받으면 생성 학습을 통해서 노이즈 제거해서 실제 분포 찾아서 값 정확하게 예측 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    for i in train:\n",
    "        train_step(i)\n",
    "        \n",
    "# generative가 공부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x204cc3facc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = generative(tf.random.normal([1,100]))\n",
    "img = img.numpy().reshape(28,28)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시처럼 trainable을 바꿔주는 작업 필요\n",
    "50번은 해야된다 함...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
