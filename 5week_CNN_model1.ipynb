{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet5\n",
    "\n",
    "논문 : Gradient-Based Learning Applied to Document Rocognition\n",
    "\n",
    "augmentation : 딥러닝 기법이 아닌 전통적인 기법\n",
    "    \n",
    "    - invariant -> CNN에서 위치에 따라 잘 맞는 것도 있지만 아닌것도(equivariance) -> invariant하게 만들기 위해\n",
    "    \n",
    "### 특징\n",
    "1. activation funciton= hyperbolic tangent\n",
    "2. optimizer = Stochastic Gradient Descent(SGD)\n",
    "    - SGD : shuffle해서 그중 한 개만 가지고 gradient desent -> local에 빠지지 않는다\n",
    "    - 속도가 빠르지만 노이즈가 있으면 성능 안 좋음\n",
    "    - sigmoid가 양수고 0~1범위로 여러 문제 -> tanh씀(-1~1)\n",
    "    - hyper dimensional(초평면)에서는 local minimum이 거의 없다 -> 요즘 거의 고려 안함\n",
    "    \n",
    "3. Average pooling\n",
    "4. learning rate decay\n",
    "\n",
    "- https://arxiv.org/abs/1406.2572\n",
    "\n",
    "\n",
    "## LeNet5 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters = 6,kernel_size=5, strides=1,\n",
    "                                activation = 'tanh', padding ='same', input_shape=(32,32,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=2,strides=2,padding = 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters = 16,kernel_size=5, strides=1,\n",
    "                                activation = 'tanh', padding ='valid'))\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=2,strides=2,padding = 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters = 120,kernel_size=5, strides=1,\n",
    "                                activation = 'tanh', padding ='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(84, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 16, 16, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 84)                40404     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 91,946\n",
      "Trainable params: 91,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(epoch):\n",
    "    lr = 5e-4\n",
    "    if epoch <=2:\n",
    "        lr = 2e-4\n",
    "    elif epoch >2 and epoch <= 5:\n",
    "        lr = 5e-5\n",
    "    elif epoch >5 and epoch <= 9:\n",
    "        lr = 1e-5\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x1d71c30d940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.optimizers.SGD(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate = learning_rate))\n",
    "\n",
    "# SGD 대문자는 class , 소문자는 function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learningrate decay : epoch을 돌 때마다 lr를 줄인다.\n",
    "\n",
    "**callback 활용!**\n",
    "- epoch 돌때마다 변화하게 하기\n",
    "\n",
    "- 에폭 하나 끝낼 때 telegram 보내는 등의 작업 가능\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "lr = LearningRateScheduler(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x,y,epochs=20,callbacks=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CA(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None): # epoch \n",
    "        print('epoch begin')\n",
    "    def on_epoch_end(self, epoch, logs=None):  # epoch 끝나면 실행\n",
    "        print('epoch end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_implements_predict_batch_hooks',\n",
       " '_implements_test_batch_hooks',\n",
       " '_implements_train_batch_hooks',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_predict_batch_begin',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_begin',\n",
       " 'on_predict_end',\n",
       " 'on_test_batch_begin',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_begin',\n",
       " 'on_test_end',\n",
       " 'on_train_batch_begin',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'set_model',\n",
       " 'set_params']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.keras.callbacks.Callback)\n",
    "# predict, batch별, train 등에서 모두 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters = 6,kernel_size=5, strides=1,\n",
    "                                activation = 'tanh', padding ='same', input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=2,strides=2,padding = 'valid'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 16,kernel_size=5, strides=1,\n",
    "                                activation = 'tanh', padding ='valid'))\n",
    "model.add(tf.keras.layers.AveragePooling2D(pool_size=2,strides=2,padding = 'valid'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 120,kernel_size=5, strides=1,\n",
    "                                activation = 'tanh', padding ='valid'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(84, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.SGD())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch begin\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.1299epoch end\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d71c4dc630>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=1,callbacks=[CA()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch begin\n",
      "\r",
      "   1/1875 [..............................] - ETA: 0s - loss: 0.4005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1006 20:47:54.638223 20056 deprecation.py:323] From C:\\Users\\Gyu\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   2/1875 [..............................] - ETA: 4:56 - loss: 0.2936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1006 20:47:54.899499 20056 callbacks.py:323] Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0100s vs `on_train_batch_begin` time: 0.0409s). Check your callbacks.\n",
      "W1006 20:47:54.900497 20056 callbacks.py:328] Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0100s vs `on_train_batch_end` time: 0.2653s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0990epoch end\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d71c51c550>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=1,callbacks=[CA(), tf.keras.callbacks.TensorBoard()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 28636."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch begin\n",
      "Epoch 1/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.9388epoch end\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.9385\n",
      "epoch begin\n",
      "Epoch 2/10\n",
      "1866/1875 [============================>.] - ETA: 0s - loss: 0.6435epoch end\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.6431\n",
      "epoch begin\n",
      "Epoch 3/10\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.5162epoch end\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5164\n",
      "epoch begin\n",
      "Epoch 4/10\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.4422epoch end\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4420\n",
      "epoch begin\n",
      "Epoch 5/10\n",
      "1867/1875 [============================>.] - ETA: 0s - loss: 0.3911epoch end\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3909\n",
      "epoch begin\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.3527epoch end\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3527\n",
      "epoch begin\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.3347epoch end\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3347\n",
      "epoch begin\n",
      "Epoch 8/10\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.3318epoch end\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3318\n",
      "epoch begin\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.3289epoch end\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3289\n",
      "epoch begin\n",
      "Epoch 10/10\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.3260epoch end\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d71d83ecc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10,callbacks=[CA(),lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "<br></br>\n",
    "\n",
    "## alexnet\n",
    "\n",
    "논문 : ImageNet Classification with Deep Convolutonal Neural Networks by Hinton\n",
    "\n",
    "- 이전보다 효율적으로 computing resource 사용\n",
    "\n",
    "### 특징\n",
    "1. GPU사용 : 하드웨어 성능 때문에 두개로 쪼갬\n",
    "2. couvolution layer\n",
    "    - stride : 4 -> 학습시간 문제로\n",
    "    - kernel size도 크다\n",
    "    - zero-padding\n",
    "    - maxpooling, overlap(window)\n",
    "    - Local Response Normalization(batch normalization)\n",
    "    - **relu** : 속도 빠름(rectified)\n",
    "    \n",
    "---\n",
    "\n",
    "### overfitting 줄이기\n",
    "\n",
    "현대의 대부분 기법의 기반임\n",
    "\n",
    "- augmentation\n",
    "\n",
    "- Dropout도 Ensemble techique이라고 할 수 있음.\n",
    "    - 학습시에만 랜덤하게 없애기 때문에 모델을 만들어도 합쳐서 하나의 최종 모델을 만든다.\n",
    "    - overfitting 줄임\n",
    "- kernel initialize\n",
    "- batch size 키우기\n",
    "- optimizer : SGD\n",
    "- learning rate decay -> Plateu(고원 현상)\n",
    "- model 여러 개 만들어 ensemble\n",
    "- weight decay\n",
    "\n",
    "## alexnet 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters = 96,kernel_size = 11,strides = 4, padding='valid'\n",
    "                                 ,kernel_regularizer=tf.keras.regularizers.l2(0.005), activation = 'relu'\n",
    "                                ,input_shape=(227,227,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.MaxPool2D(pool_size=3,strides=2,padding='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(tf.keras.layers.LRN  local regualr normal\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256,kernel_size = 3,strides = 1, padding='valid'\n",
    "                                 ,kernel_regularizer=tf.keras.regularizers.l2(0.005), activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=3,strides=2,padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters = 384,kernel_size = 3,strides = 1, padding='same'\n",
    "                                 ,kernel_regularizer=tf.keras.regularizers.l2(0.005), activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=3,strides=1,padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 25, 25, 256)       221440    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 64896)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4096)              265818112 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 271,056,616\n",
      "Trainable params: 271,056,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.01,momentum=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = tf.keras.callbacks.ReduceLROnPlateau()\n",
    "\n",
    "# Plateau 현상이 일어나면 lr을 줄임.\n",
    "# 변하지 않으면  (min_delta) lr를 10퍼씩 줄이기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
