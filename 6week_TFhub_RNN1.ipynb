{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 되는지 안되는지 Feasibility test\n",
    "    - 경량화해야함!(정확도는 유지하고 연산을 줄이는)\n",
    "    - 복잡한 모델을 간단하게\n",
    "- 알고리즘 경량화\n",
    "    - 파라미터의 크기를 줄임.\n",
    "    \n",
    "<br>\n",
    "\n",
    "## tfhub\n",
    "https://tfhub.dev/\n",
    "    - tensorflow에서 모델 제공\n",
    "\n",
    "https://modelzoo.co/\n",
    "\n",
    "- tf.keras.applications 에 있는 건 적은 편이다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorflow-hub\n",
    "# 설치는 - 사용은  _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ImageModuleInfo',\n",
       " 'KerasLayer',\n",
       " 'LatestModuleExporter',\n",
       " 'LooseVersion',\n",
       " 'Module',\n",
       " 'ModuleSpec',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_run',\n",
       " 'absolute_import',\n",
       " 'add_signature',\n",
       " 'attach_image_module_info',\n",
       " 'attach_message',\n",
       " 'compressed_module_resolver',\n",
       " 'config',\n",
       " 'create_module_spec',\n",
       " 'create_module_spec_from_saved_model',\n",
       " 'division',\n",
       " 'estimator',\n",
       " 'eval_function_for_module',\n",
       " 'feature_column',\n",
       " 'feature_column_v2',\n",
       " 'get_expected_image_size',\n",
       " 'get_num_image_channels',\n",
       " 'image_embedding_column',\n",
       " 'image_module_info_pb2',\n",
       " 'image_util',\n",
       " 'keras_layer',\n",
       " 'load',\n",
       " 'load_module_spec',\n",
       " 'logging',\n",
       " 'meta_graph_lib',\n",
       " 'module',\n",
       " 'module_attachment_pb2',\n",
       " 'module_def_pb2',\n",
       " 'module_impl',\n",
       " 'module_spec',\n",
       " 'module_v2',\n",
       " 'native_module',\n",
       " 'print_function',\n",
       " 'register_module_for_export',\n",
       " 'registry',\n",
       " 'resolve',\n",
       " 'resolver',\n",
       " 'saved_model_lib',\n",
       " 'saved_model_module',\n",
       " 'sparse_text_embedding_column',\n",
       " 'tensor_info',\n",
       " 'text_embedding_column',\n",
       " 'text_embedding_column_v2',\n",
       " 'tf',\n",
       " 'tf_utils',\n",
       " 'tf_v1',\n",
       " 'version']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hub)\n",
    "# KerasLayer 등 layer\n",
    "# multi input, output 되는 것도 sequence안에 넣을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_035_224/classification/4',\n",
    "                      input_shape=(224,224,3))\n",
    "# tensorflow version 확인\n",
    "# cache 기법이 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(layer, tf.keras.layers.Layer)\n",
    "# 내부적으로 keras layer로 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input layer\n",
    "2. KerasLayer 에서 input_shape 지정\n",
    "3. model.build로 input_shape 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layer\n",
    "])\n",
    "\n",
    "# summary 에러나면 input이 없다는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_2 (KerasLayer)   (None, 1001)              1692489   \n",
      "=================================================================\n",
      "Total params: 1,692,489\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,692,489\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary 에러나면 input이 없다는 뜻\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2 = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_035_224/classification/4')\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    layer2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.build((None,224,224,3))\n",
    "# 처음에 input 안하고 동적으로 input맞추기\n",
    "# build시키면 그 값으로 기억"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_4 (KerasLayer)   (None, 1001)              1692489   \n",
      "=================================================================\n",
      "Total params: 1,692,489\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,692,489\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_4 (KerasLayer)   (None, 1001)              1692489   \n",
      "=================================================================\n",
      "Total params: 1,692,489\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,692,489\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.build((None,222,222,3))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.Input((224,224,3)),\n",
    "    layer2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.built # build했는지, input넣어도 True나옴\n",
    "# built가 안되면 summary가 안나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_4 (KerasLayer)   (None, 1001)              1692489   \n",
      "=================================================================\n",
      "Total params: 1,692,489\n",
      "Trainable params: 1,678,409\n",
      "Non-trainable params: 14,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.trainable = True\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\n",
      "65536/61306 [================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "x = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =Image.open(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1001), dtype=float32, numpy=\n",
       "array([[-0.0786503 , -0.08302835, -1.9932742 , ..., -0.09836095,\n",
       "        -0.20876181,  2.6551542 ]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.array(data.resize((224,224)))[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "918"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model(np.array(data.resize((224,224)))[np.newaxis]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comic book\n"
     ]
    }
   ],
   "source": [
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "with open(labels_path) as f:\n",
    "    print(f.read().splitlines()[918])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(data.resize((224,224)))\n",
    "p=p/255\n",
    "p = np.expand_dims(p,0)\n",
    "np.argmax(model(p).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "military uniform\n"
     ]
    }
   ],
   "source": [
    "with open(labels_path) as f:\n",
    "    print(f.read().splitlines()[653])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Gyu\\\\.keras\\\\datasets\\\\flower_photos'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = tf.keras.utils.get_file(\n",
    "  'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "   untar=True)\n",
    "data_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 구축하는 방법\n",
    "1. 이미지 형태 directory \n",
    "2. pandas DataFrame으로 관리(우아함)\n",
    "  - EDA도 용이\n",
    "  - tf 연동\n",
    "3. HDF5 \n",
    "4. imagedb\n",
    "\n",
    "<br>\n",
    "\n",
    "tf.keras.preprocessing.image_dataset_from_directory -> tensor로 관리\n",
    "    - Autotune 등 학습 최적화\n",
    "    - map 등 사용 가능하지만 사용이 어려움, augment하기엔 어려움\n",
    "    \n",
    "\n",
    "tf.keras.preprocessing.image.ImageDataGenerator : python 형태(numpy)로 바꿈\n",
    "    - generator할 때마다 형태를 바꿈(augmentation 편리)\n",
    "    \n",
    "tf.keras.layers.experimental.preprocessing.\n",
    "    - layer로 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image_dataset_from_directory(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "# gen은 adaptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x2495ef23c88>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.flow_from_directory(data_root)\n",
    "# dataframe : pandas 연동\n",
    "# python 기반 generator 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfhub\n",
    "- classification : 모델 전체를 가져옴\n",
    "- feature-vector : fully connected 없음\n",
    "\n",
    "### transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headless model\n",
    "fx = hub.KerasLayer('https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = tf.keras.models.Sequential([\n",
    "    tf.keras.Input((224,224,3)),\n",
    "    fx,\n",
    "#     tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(5, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_5 (KerasLayer)   (None, 1792)              17673816  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 8965      \n",
      "=================================================================\n",
      "Total params: 17,682,781\n",
      "Trainable params: 8,965\n",
      "Non-trainable params: 17,673,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor는 학습방법 5가지\n",
    "\n",
    "1. fit\n",
    "2. fit_generator\n",
    "3. train_on_batch(GAN할 때 사용)\n",
    "4. Gradient Tape\n",
    "5. estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n",
      "Epoch 1/2\n",
      "115/115 [==============================] - 372s 3s/step - loss: 1.5069 - acc: 0.3708\n",
      "Epoch 2/2\n",
      "115/115 [==============================] - 363s 3s/step - loss: 1.2848 - acc: 0.5918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249d5404a58>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen = gen.flow_from_directory(data_root)\n",
    "mo.fit_generator(image_gen,epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN(Recurrent Neural Network)\n",
    "- 순환적 신경망(재귀X)\n",
    "- **상태가 중심이 된다** -> 순차적인(시간적인 상황이 결합)\n",
    "    - CNN, DNN은 시점에 상관없이 같은 결과를 내지만 RNN은 시간적인 상황에 따라 나오는 모델\n",
    "- 앞에 발생한 것이 일정하게 영향을 미친다는 가정(CNN의 shared weight랑 비슷한 개념)\n",
    "\n",
    "</br>\n",
    "\n",
    "**State와 State Transition(상태 변화)로 표현하는데 이것을 찾는 모델**\n",
    "> 연속으로 일어나는 변화를 학습을 통해 찾음 -> hidden state 찾기!\n",
    "\n",
    "- ML은 데이터 간 독립이라는 가정\n",
    "- RNN은 데이터가 독립이 아니어도 상관없음\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "상태와 상태변이 곱 + BIAS\n",
    "- 현재시점 t 에서의 hidden state: $h_t=tanh(W_{hh} h_{t-1}+W_{xh} x_t)$\n",
    "- 현재시점 t 에서의 output: $y_t=W_{hy}h_t$\n",
    "\n",
    "같은 음식인데 맛을 다르게 느끼는 이유는 상태가 다르기 때문(입력이 다르기 때문)\n",
    "    - 시점마다 상태도 달라서 output도 다르다\n",
    "\n",
    "다른 모델에 비해 인과관계가 없음\n",
    "\n",
    "- U : 전\n",
    "- V : 후\n",
    "- W : State Transition\n",
    "\n",
    "---\n",
    "\n",
    "## 활용 방법\n",
    "\n",
    "1. 1to1\n",
    "   - vanilla NN\n",
    "2. 1 to many\n",
    "   - Image Captioning \n",
    "3. many to 1\n",
    "   - Sentiment Classifiction\n",
    "4. many to many( synched/unsynched)\n",
    "   - Video Classification on frame level \n",
    "   - Machine Translation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
